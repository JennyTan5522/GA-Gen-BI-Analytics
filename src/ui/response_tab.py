import streamlit as st
import json
from typing import Optional, List
from streamlit_feedback import streamlit_feedback
from langchain.agents import create_react_agent, AgentExecutor
from src.tools.custom_sql_toolkit import CustomSQLToolkit
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
from langchain_core.documents import Document
from uuid import uuid4
from pydantic import BaseModel, Field
from data.const import WARNING_MESSAGE
from src.ui.setup_st_config import is_data_and_llm_connected
from src.ui.document_tab import add_documents_to_vector_store
from data.const import TEXT_TO_SQL_TO_CHART_PROMPT_TEMPLATE, PYTHON_PLOT_PROMPT_TEMPLATE, FIX_FINAL_RESPONSE_TEMPLATE
from config.logger import get_logger

logger = get_logger(__name__)

class FinalAnswerFormat(BaseModel):
    SQL: List[str] = Field("SQL Queries", description="A list of one or more SQL queries generated by the LLM to answer the user's question")
    TextResponse: str = Field("Text Response", description="A concise, human-readable explanation of the SQL results, including business insights or findings")
    Code: str = Field("Code Block", description="A Python code block (typically using Plotly and Streamlit) to visualize the SQL results")
    FollowUpQuestions: List[str] = Field("Follow Up Data Analysis Questions", description="A list of suggested follow-up data analysis questions to guide the user toward deeper insights")

class ResponseTab:
    def __init__(self):
        """Initialize and handle the response tab UI."""
        if not is_data_and_llm_connected():
            st.warning(WARNING_MESSAGE)
            return

        self.handle_response_tab()

    def final_response_output_parser(self, response_text: str):
        """Parse agent's response text into structured format using Pydantic.

        Args:
            response_text: The output text from the agent's response.

        Returns:
            Tuple containing SQL, text response, code block, follow-up questions, and final answer as string.
        """
        try:
            logger.debug(f"Response Text: {response_text}")
            output_parser = PydanticOutputParser(pydantic_object=FinalAnswerFormat)
            final_answer_pydantic_format = output_parser.invoke(response_text)
            sql = final_answer_pydantic_format.SQL
            text_response = final_answer_pydantic_format.TextResponse
            code_block = final_answer_pydantic_format.Code
            follow_up_questions = final_answer_pydantic_format.FollowUpQuestions
            logger.debug(f"Final Answer: \n{final_answer_pydantic_format}")
            final_answer_str_format = json.dumps(final_answer_pydantic_format.dict(), indent=4)
            st.session_state.feedback = None
            return sql, text_response, code_block, follow_up_questions, final_answer_str_format
        except Exception as e:
            logger.error(f"Error parsing final response: {e}")
            st.error(f"Error parsing final response: {e}")

    def rag_top_k_related_documents(self, query: str, k: int = 3) -> str:
        """Retrieve top k related documents from the vector store for a query.

        Args:
            query: The user's query to search for related documents.
            k: Number of top related documents to retrieve.

        Returns:
            String of top-k retriever documents based on the user's query.
        """
        try:
            if "retriever" in st.session_state:
                retriever_results = st.session_state.retriever.invoke(query)[:k]
                formatted_retriever_results = "\n\n".join(
                    f"Doc {i+1}:\n{doc.page_content}\nMetadata: {doc.metadata}"
                    for i, doc in enumerate(retriever_results)
                )
                return formatted_retriever_results
            return ""
        except Exception as e:
            logger.error(f"Error while retrieving the top-k documents: {e}")
            st.error(f"Error while retrieving the top-k documents: {e}")

    def react_agent_toolkit(self, retriever_top_k_documents: str, additional_feedbacks: Optional[str] = None):
        """Create and configure a ReAct agent toolkit for SQL, Python, and response validation.

        Args:
            retriever_top_k_documents: Top-k related documents from the vector store.
            additional_feedbacks: Additional feedback/context from user for the prompt.

        Returns:
            AgentExecutor capable of handling complex queries and reasoning through multiple tools.
        """
        try:
            db_toolkit = CustomSQLToolkit(db=st.session_state.db, llm=st.session_state.llm)
            tools = db_toolkit.get_tools()
            paired_history_messages = []
            latest_k_chat_history = ""

            # Pair user and assistant messages for chat history context
            for i in range(1, len(st.session_state.messages) - 1, 2):
                if st.session_state.messages[i]['role'] == "user" and st.session_state.messages[i+1]['role'] == "assistant":
                    paired_history_messages.append((st.session_state.messages[i]['content'], st.session_state.messages[i + 1]['content']))

            latest_k_pairs = paired_history_messages[-st.session_state.k:]
            for idx, (human, ai) in enumerate(latest_k_pairs, 1):
                latest_k_chat_history += f"--- Chat {idx} ---\n"
                latest_k_chat_history += f"User: {human}\n"
                try:
                    content_json = json.loads(ai)
                    sql = content_json.get("SQL")
                    text_response = content_json.get("TextResponse")
                    if sql:
                        latest_k_chat_history += f"Assistant (SQL): {sql}\n\n"
                    else:
                        latest_k_chat_history += f"Assistant (TextResponse): {text_response}\n\n"
                except json.JSONDecodeError:
                    latest_k_chat_history += f"Assistant: {ai}\n\n"

            # Build table info context for prompt
            table_info_prompt_template = ""
            # if st.session_state.tables_info and len(st.session_state.tables_info) > 0:
            #     all_tables_info = self.get_table_info(st.session_state.tables_info)
            #     table_info_prompt_template += "\nThe following context provides detailed information about the database tables and their columns.\n"
            #     table_info_prompt_template += "Use this information to accurately generate SQL queries.\n"
            #     table_info_prompt_template += "## Table Context Information\n"
            #     table_info_prompt_template += f"\n{all_tables_info}"

            prompt_template = PromptTemplate.from_template(
                TEXT_TO_SQL_TO_CHART_PROMPT_TEMPLATE,
                partial_variables={
                    "python_plot_instructions": PYTHON_PLOT_PROMPT_TEMPLATE,
                    "table_names": st.session_state.db.get_table_names(),
                    "db": st.session_state.db,
                    "top_k": str(10),
                    "dialect": st.session_state.db.dialect,
                    "retriever_top_k_documents": retriever_top_k_documents,
                    "additional_table_info": table_info_prompt_template,
                    "additional_feedbacks": additional_feedbacks,
                    "plotly_unique_key": str(int((len(st.session_state.messages) + 1)/2)),
                    "chat_history": latest_k_chat_history,
                },
            )
            logger.debug(f"Prompt Template: \n{prompt_template.template}")

            react_agent = create_react_agent(
                llm=st.session_state.llm,
                tools=tools,
                prompt=prompt_template,
            )

            agent_executor = AgentExecutor(
                agent=react_agent,
                tools=tools,
                verbose=True,
                memory=st.session_state.memory,
                handle_parsing_errors=True,
                max_iteration=50,
                max_execution_time=500,
                return_intermediate_steps=True
            )
            return agent_executor
        except Exception as e:
            logger.error(f"Error creating ReAct agent toolkit: {e}")
            st.error(f"Error creating ReAct agent toolkit: {e}")

    def invoke_agent_response(self, agent_executor: AgentExecutor, user_query: str, user_feedback: str = "", is_user_feedback: bool = False):
        """Invoke the agent to generate a response and return the message and response text.

        Args:
            agent_executor: The agent executor configured with tools and prompts.
            user_query: The query provided by the user.
            user_feedback: Additional feedback or request from the user.
            is_user_feedback: Indicates if the query includes user feedback.

        Returns:
            Tuple containing the message used for the agent and the agent's response text.
        """
        try:
            if is_user_feedback:
                query_input = f"Previous User Question: {user_query}\nCurrent User Feedback or Request: {user_feedback}"
                return_message = user_feedback
            else:
                query_input = return_message = user_query

            response_text = agent_executor.invoke({"input": query_input})
            return return_message, response_text
        except Exception as e:
            logger.error(f"Error invoking agent response: {e}")
            st.error(f"Error invoking agent response: {e}")

    def display_agent_thinking(self, agent_thoughts):
        """display the agent's reasoning steps in the UI.

        Args:
            agent_thoughts: List of agent reasoning steps.
        """
        st.markdown("""
            <style>
            div[data-testid="stExpander"] div[role="button"] p {
                font-size: 1.2rem;
                font-weight: bold;
            }
            pre code {
                white-space: pre-wrap !important;
            }
            </style>
        """, unsafe_allow_html=True)

        for i, step in enumerate(agent_thoughts, 1):
            with st.expander(f"Step {i}: Thinking Process", expanded=False):
                if isinstance(step, tuple) and len(step) >= 2:
                    action, observation = step[0], step[1]
                    st.markdown(f"*Action:* {action.tool}")
                    st.markdown(f"*Input:*\n\n{action.tool_input}\n")
                    st.markdown(f"*Observation:*\n\n{observation}\n")
                else:
                    st.json(step)

    def handle_user_feedback(self, user_query: str, message_index: int):
        """
        Processes user feedback for the last response and either regenerates the agent's answer if negative or saves it to the vector store if positive.

        Args:
            user_query (str): The user's original query.
            message_index (int): The feedback message index in session state.
        """
        if not len(st.session_state.memory.chat_memory.messages) > 0:
            return
        
        last_message = st.session_state.memory.chat_memory.messages[-1]
        feedback_response = ""
 
        if hasattr(last_message, "content") and last_message.content:
            try:
                final_answer = json.loads(last_message.content)
                sql_query = final_answer.get("SQL", None)
                text_response = final_answer.get("TextResponse", None)
                feedback_response = (f"\n Previous SQL Query or Previous Answer: {sql_query if sql_query else text_response}")
            except:
                feedback_response = (f"\n Previous SQL Query or Previous Answer: {last_message.content}")

            feedback_key = f"feedback_{message_index}"
            if feedback_key not in st.session_state:
                return
            
            feedback = st.session_state[feedback_key]
            if not feedback:
                return
        
            feedback_score = feedback['score']
            feedback_text = feedback['text']
         
            # If the feedback is thumbs down, regenerate the response
            if feedback_score == "👎":
                if feedback_text:
                    feedback_response += f"\n Current User Feedback or Request: {feedback_text}"
                else:
                    feedback_response += f"\n Current User Feedback or Request: The previous answer is not satisfactory. Please re-check the user request and provide a better response."

                retriever_top_k_documents = self.rag_top_k_related_documents(feedback_response)
                agent_executor = self.react_agent_toolkit(retriever_top_k_documents = retriever_top_k_documents, additional_feedbacks = self.regenerate_final_answer_prompt(feedback_response))
                user_query, response_output = self.invoke_agent_response(agent_executor, user_query, feedback_text, is_user_feedback = True)
                sql, text_response, code_block, follow_up_questions, final_answer_str_format = self.final_response_output_parser(response_output["output"])
                self.saved_user_message(user_query, final_answer_str_format, response_output["intermediate_steps"])
            else:
                page_content = {"User Query": user_query, "SQL Query": sql_query}
                sql_query_document = [Document(page_content=json.dumps(page_content), metadata={"table_name": st.session_state.selected_table})]
                uuids = [str(uuid4())]
                add_documents_to_vector_store(sql_query_document, uuids, page_content)

        st.session_state.feedback = True

    def display_response(self, sql: List[str], response: str, code_block: str, follow_up_questions: List[str], agent_thoughts: Optional[str] = None):
        """Display SQL results, response, code, follow-up questions, and agent reasoning in Streamlit UI.

        Args:
            sql: List of SQL queries used to generate the response.
            response: The textual response generated from the SQL query or retrieval process.
            code_block: A Python code block that generates a visualization.
            follow_up_questions: Suggested follow-up questions for further analysis.
            agent_thoughts: Agent's reasoning or steps taken to arrive at the final answer.
        """
        try:
            sql_is_blank = len(sql) == 0
            code_is_blank = not code_block.strip()

            # If both SQL and code are blank, show response only
            if sql_is_blank and code_is_blank and len(follow_up_questions) == 0:
                st.markdown(f"Response:\n{response}")
                return

            if not code_is_blank:
                compiled_code = compile(code_block, '<string>', 'exec')
                chart_tab, sql_tab, code_tab, followup_tab, agent_tab = st.tabs([
                    "📊 Chart", "🛢 SQL", "💻 Code", "💡 Follow Up Analysis Questions", "🧠 Agent Thinking"
                ])

                with chart_tab:
                    local_scope = {}
                    exec(code_block, {}, local_scope)

                with sql_tab:
                    if not sql_is_blank:
                        for query in sql:
                            st.code(query, language="sql")
                    if response and "blank" not in response.lower():
                        st.markdown(f"Response: \n{response}")

                with code_tab:
                    formatted_code = code_block.replace(";", ";\n").replace("import", "\nimport")
                    st.code(formatted_code, language="python")

                with followup_tab:
                    if follow_up_questions:
                        for question in follow_up_questions:
                            st.markdown(f"- {question}")
                    else:
                        st.info("No follow-up questions generated.")

                with agent_tab:
                    if agent_thoughts:
                        self.display_agent_thinking(agent_thoughts)
                    else:
                        st.info("No agent reasoning provided.")
            else:
                sql_tab, followup_tab, agent_tab = st.tabs(["🛢 SQL", "💡 Follow Up Analysis Questions", "🧠 Agent Thinking"])

                with sql_tab:
                    if not sql_is_blank:
                        for query in sql:
                            st.code(query, language="sql")
                    if response and "blank" not in response.lower():
                        st.markdown(f"Response: \n{response}")

                    with followup_tab:
                        if len(follow_up_questions) > 0:
                            for question in follow_up_questions:
                                st.markdown(f"- {question}")
                        else:
                            st.info("No follow-up questions generated.")

                with agent_tab:
                    if agent_thoughts:
                        self.display_agent_thinking(agent_thoughts)
                    else:
                        st.info("No agent reasoning provided.")
        except Exception as e:
            logger.error(f"An error occurred while displaying the response: {e}")
            st.error(f"An error occurred while displaying the response: {e}")

    def saved_user_message(self, user_query: str, final_answer_str_format: str, agent_thoughts: str):
        """Save the user query and final answer in the session state messages.

        Args:
            user_query: The original query provided by the user.
            final_answer_str_format: The final answer in string format.
            agent_thoughts: The agent's reasoning or steps taken to arrive at the final answer.
        """
        try:
            st.session_state.messages.append({"role": "user", "content": user_query})
            st.session_state.messages.append({"role": "assistant", "content": final_answer_str_format, "agent_thinking_process": agent_thoughts})
        except Exception as e:
            logger.error(f"Error saving user message: {e}")

    def display_feedback_form(self, user_query: str):
        """Display a feedback form for users to provide feedback on the LLM response.

        Args:
            user_query: The original query provided by the user.
        """
        try:
            message_index = int((len(st.session_state.messages) + 1)/2)
            key = f"feedback_{message_index}"
            with st.form(f"feedback_form_{message_index}"):
                streamlit_feedback(
                    feedback_type="thumbs",
                    optional_text_label="[Optional] 👍 Save this response for feedback reference 👎 Regenerate or provide corrections",
                    align="flex-start",
                    key=key
                )
                st.form_submit_button('Submit Response', on_click=lambda: self.handle_user_feedback(user_query, message_index))
        except Exception as e:
            logger.error(f"Error displaying feedback form: {e}")

    def fix_final_answer(self, original_response: str, error_msg: str):
        """Use LLM to fix the final response if parsing fails.

        Args:
            original_response: The original response generated by the LLM.
            error_msg: The error message encountered during parsing.

        Returns:
            The corrected response in the required JSON format.
        """
        try:
            fixed_prompt_template = ChatPromptTemplate.from_template(FIX_FINAL_RESPONSE_TEMPLATE)
            chain = fixed_prompt_template | st.session_state.llm | StrOutputParser()
            fixed_response = chain.invoke({"original_response": original_response, "error_message": error_msg})
            logger.debug(f"Fixed Response: {fixed_response}")
            return fixed_response
        except Exception as e:
            logger.error(f"An error occurred while fixing the final answer: {e}")
            st.error(f"An error occurred while fixing the final answer: {e}")

    def handle_response_tab(self):
        """Main logic for the response tab, including chat history and feedback."""
        try:
            if "messages" not in st.session_state:
                st.session_state["messages"] = [{"role": "assistant", "content": "Hello! I'm your SQL Assistant. How can I assist you today?"}]
                logger.debug("Session messages initialized.")
                st.session_state["selected_mode"] = "SQL to Chart 📊"

            last_query = ""
            for idx, message in enumerate(st.session_state.messages):
                role = message.get("role")
                if role == "user":
                    with st.chat_message("user"):
                        content = message["content"]
                        last_query = content
                        st.write(content)
                if role == "assistant":
                    with st.chat_message("assistant"):
                        content = message["content"]
                        try:
                            content_json = json.loads(content)
                            logger.debug(f"Content JSON: {content_json}")
                            self.display_response(
                                content_json['SQL'],
                                content_json['TextResponse'],
                                content_json['Code'],
                                content_json['FollowUpQuestions'],
                                message["agent_thinking_process"]
                            )
                        except Exception:
                            st.write(content)

            if len(st.session_state.messages) > 1 and st.session_state.feedback:
                self.display_feedback_form(last_query)
                st.session_state.feedback = False

            # Style to fix the chatbot position
            st.markdown(
                """
                <style>
                .stChatInput {
                    position: fixed;
                    bottom: 25px;
                    left: 430px;
                    width: calc(100% - 430px);
                    background-color: white;
                    padding: 10px;
                    box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.1);
                    z-index: 1000;
                    border-radius: 10px;
                }
                .disclaimer {
                    position: fixed;
                    bottom: 0px;
                    margin-bottom: -5px;
                    left: 350px;
                    width: calc(100% - 350px);
                    font-size: 11px;
                    color: gray;
                    text-align: center;
                    background-color: white;
                    padding: 5px 10px;
                    z-index: 999;
                }
                .stRadio > div {
                    display: flex;
                    gap: 10px;
                    align-items: center;
                    margin-bottom: 10px;
                }
                </style>
                """,
                unsafe_allow_html=True,
            )

            st.markdown(
                """
                <p class="disclaimer">
                    <strong> Disclaimer:</strong> Gen BI system may make mistakes; review results and use your judgment. 
                </p>
                """,
                unsafe_allow_html=True,
            )

            user_query = st.chat_input(placeholder="Ask me anything!")

            if user_query:
                st.chat_message("user").write(user_query)
                with st.chat_message("assistant"):
                    with st.spinner("We are preparing a response to your question. Please allow up to one minute for completion...."):
                        MAX_RETRIES = 3
                        attempt = 0
                        while attempt < MAX_RETRIES:
                            try:
                                retriever_top_k_documents = self.rag_top_k_related_documents(user_query)
                                agent_executor = self.react_agent_toolkit(retriever_top_k_documents=retriever_top_k_documents)
                                user_query, response_output = self.invoke_agent_response(agent_executor, user_query)
                                sql, text_response, code_block, follow_up_questions, final_answer_str_format = self.final_response_output_parser(response_output["output"])
                                self.display_response(sql, text_response, code_block, follow_up_questions, response_output["intermediate_steps"])
                                self.saved_user_message(user_query, final_answer_str_format, response_output["intermediate_steps"])
                                self.display_feedback_form(user_query)
                                break
                            except Exception as e:
                                try:
                                    logger.error(f"Error while generating response. Now fixing: {e}")
                                    attempt += 1
                                    fix_output = self.fix_final_answer(original_response=response_output["output"], error_msg=e)
                                    sql, text_response, code_block, follow_up_questions, final_answer_str_format = self.final_response_output_parser(fix_output)
                                    self.display_response(sql, text_response, code_block, follow_up_questions, response_output["intermediate_steps"])
                                    self.saved_user_message(user_query, final_answer_str_format, response_output["intermediate_steps"])
                                    break
                                except Exception as e:
                                    logger.error(f"Error while generating response. Now fixing: {e}")
                                    st.error(f"Error while processing response. Please try again.")
                                    break
                        else:
                            st.error("Failed to generate a response after multiple attempts. Please check your query or try again later.")
                            logger.error("Failed to generate a response after multiple attempts.")
        except Exception as e:
            logger.error(f"Error in handle_response_tab: {e}")
            st.error(f"Error in handle_response_tab: {e}")