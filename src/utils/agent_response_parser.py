import json
from typing import Optional
from pydantic import BaseModel, Field
from notebooks.Logger_Manager import logger

class ResponseSchema(BaseModel):
    class Config:
        arbitrary_types_allowed = True 

    """Final response to the question being asked"""
    SQL: str = Field(
        description="Provide the SQL query that answers the user's question, formatted as plain text without comments or any code block wrappers. Leave this field blank if an SQL query is not applicable or unnecessary for the query."
    )
    
    TextResponse: str = Field(
        description="Provide one of the following depending on the context of the query:\n1. A general answer addressing the user's question directly.\n2. A follow-up question to clarify ambiguities or missing details in the query.\n3. A detailed explanation and analysis of the query result, including trends, patterns, and actionable insights where applicable."
    )
    
    Code: str = Field(
        description="Provide Python code to generate chart visualizations and display the relevant DataFrame, without include the 'python' wrapper or '' at the beginning and end of the code.  The code must be executable and include proper imports, ensuring clear visual representation of the data (e.g., bar charts, line charts, pie charts). Leave this field blank if no code is necessary. "
    )

class CustomResponseParser:
    def parse(self, llm_generated_answer: str):
        """
        Parses and validates the LLM-generated answer, formatting it into a structured response.

        Args:
            llm_generated_answer (str): The raw response generated by the LLM.

        Returns:
            tuple:
                - final_answer_pydantic_format (ResponseSchema): The structured response in Pydantic model format, including attributes like SQL, TextResponse, and Code.
                - final_answer_str_format (str): The JSON-serialized version of the parsed response, containing SQL, TextResponse, and Code as a JSON string. 

        Description:
            1. Removes the 'Final Answer' if present.
            2. Validates and parses the answer using the Reponse Schema
            3. Attempts to serialize the parsed response into a JSON string format.
            4. Handle edge cases like Agent thinking limit or other responses that are not in the expected format.
        """

        logger.debug(f"LLM Generated Text: \n{llm_generated_answer}")

        llm_generated_answer = llm_generated_answer.split("Final Answer:")[-1].strip() if "Final Answer:" in llm_generated_answer else llm_generated_answer.strip()

        # Parse the LLM generated answer
        try:
            print("Before Final Answer: ", llm_generated_answer)
            final_answer_pydantic_format = ResponseSchema.model_validate_json(llm_generated_answer)
            print("After Generated Answer: ", final_answer_pydantic_format)

            # Validate that the LLM response is JSON serializable (dumps = Convert JSON format to str)
            try:
                final_answer_str_format = json.dumps({
                    "SQL": final_answer_pydantic_format.SQL,
                    "TextResponse": final_answer_pydantic_format.TextResponse,
                    "Code": final_answer_pydantic_format.Code
                })
            except Exception as e:
                logger.error(f"Error in JSON serialization when parsing the Final Answer: {e}")
        except:
            pydantic_answer = f"""
                {{
                "SQL": "",
                "TextResponse": "{llm_generated_answer}",
                "Code": ""
                }}
            """
            final_answer_pydantic_format = ResponseSchema.model_validate_json(pydantic_answer)

            final_answer_str_format = json.dumps({
                    "SQL": "",
                    "TextResponse": llm_generated_answer,
                    "Code": ""
            })

        logger.debug(f"Final Answer: \n{final_answer_pydantic_format}")

        return final_answer_pydantic_format, final_answer_str_format