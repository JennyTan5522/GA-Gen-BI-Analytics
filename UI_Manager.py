# Standard Libraries
import os
import json
from typing import Optional, List

# Core Libraries
import streamlit as st
from streamlit_feedback import streamlit_feedback
from pydantic import BaseModel, Field

# Analysis Libraries
import pandas as pd
import numpy as np

# LangChain Core and Community Modules
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.documents import Document
from uuid import uuid4
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain.retrievers import EnsembleRetriever
from langchain.agents import create_react_agent, AgentExecutor
from langchain_core.messages import HumanMessage
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from langchain_core.output_parsers import StrOutputParser
from langchain.vectorstores import Chroma
from langchain.retrievers import BM25Retriever, EnsembleRetriever

import sys
import pysqlite3
sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")

import chromadb
from langchain_anthropic import ChatAnthropic
from sentence_transformers import SentenceTransformer
import asyncio

# Custom Modules
from const import (
    WARNING_MESSAGE,
    TEXT_TO_SQL_TO_CHART_PROMPT_TEMPLATE,
    PYTHON_PLOT_PROMPT_TEMPLATE,
    FIX_FINAL_RESPONSE_TEMPLATE
)
from utils.agent_response_parser import CustomResponseParser
from tools.dataset_summary_tool import dataset_summary_async
from tools.question_recommendation_tool import generate_question_recommendations_async

class SBERTEmbeddingFunction:
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')

    def embed_query(self, text):
        return self.model.encode(text).tolist()

    def embed_documents(self, texts):
        return self.model.encode(texts).tolist()
    
class FinalAnswerFormat(BaseModel):
    SQL: List[str] = Field("SQL Queries", description="A list of one or more SQL queries generated by the LLM to answer the user's question")
    TextResponse: str = Field("Text Response", description="A concise, human-readable explanation of the SQL results, including business insights or findings")
    Code: str = Field("Code Block", description="A Python code block (typically using Plotly and Streamlit) to visualize the SQL results")
    FollowUpQuestions: List[str] = Field("Follow Up Data Analysis Questions", description="A list of suggested follow-up data analysis questions to guide the user toward deeper insights")

class UIManager:
    def __init__(self, app):
        self.app = app
        self.custom_parser = CustomResponseParser()
     
    def configure_streamlit(self):
        st.set_page_config(page_title = "GenBI", page_icon = "ðŸ“Š", layout = "wide")

    def configure_session_state(self):
        """
        Initializes default values in Streamlit session state if not already set.
        """
        defaults = {
            "k": 5,
            "memory": ConversationBufferWindowMemory(
                memory_key = 'chat_history',
                k = 5,
                return_messages = True,
            ),
            "tables_info": {},
            "embedding_function": SBERTEmbeddingFunction(),
            "feedback": False
        }
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value

    def configure_sidebar(self):
        """
        Configures the Streamlit sidebar with options for data connection, API key setup, and clearing message history.
        """
        with st.sidebar:
            st.markdown("## âš™ Settings")
            st.write("Configure your settings below.")
            
            # Data Connection
            with st.expander("Connect to Data", expanded=True):
                connection_type = st.selectbox("Choose connection type", ("Upload CSV/Excel", "Connect to Database"))

                if connection_type == "Upload CSV/Excel":
                    data = st.file_uploader("\U0001F4BB Load an Excel file:", type=["csv", "xlsx"])
                    if data:
                        st.session_state.data = data
                        self.app.data_manager.excel_data_connection()

                elif connection_type == "Connect to Database":
                    self.app.data_manager.handle_database_connection()

            st.markdown("---")

            # Model Connection
            try:
                st.title("API Access")
                
                # Input field for Claude API key
                claude_api_key = st.text_input("Enter your Claude API Key:", type="password")

                if st.button("Connect to Claude API"):
                    if claude_api_key:
                        try:
                            claude_llm = ChatAnthropic(
                                api_key=claude_api_key,
                                model="claude-3-5-sonnet-20241022",
                                temperature=0,
                                max_tokens=8000
                            )

                            # Test the key is correct or not
                            response = claude_llm([HumanMessage(content="Hello")])
                            st.session_state.llm = claude_llm
                            st.success("âœ… Successfully connected to Claude API.")
                            # if "excel_summary" not in st.session_state and "question_recommendations" not in st.session_state:
                            #     self.generate_dataset_overview()

                        except Exception as e:
                            st.error(f"âŒ Failed to connect to Claude API: {e}")
                    else:
                        st.warning("âš ï¸ Please enter your Claude API key before connecting.")

            except:
                st.error("Error while connecting to LLM Model.")

            # Memory Settings
            st.sidebar.write("ðŸ›  Memory Settings")
            st.session_state.k = st.slider("Memory Size", 1, 10, st.session_state.k)

            # Clear History Button
            if st.button("ðŸ—‘ Clear Message History"):
                if "messages" in st.session_state:
                    st.session_state.messages = []
                if "memory" in st.session_state:
                    st.session_state.memory.clear()  
                st.success("Message history cleared!")

    def display_tabs(self):
        response_tab, data_tab, document_tab = st.tabs(["ðŸ’¬ Response View", "ðŸ“œ Data Explorer", "ðŸ“„ Document Explorer"])
        
        with response_tab:
            self.handle_response_tab()

        with data_tab:
            self.handle_data_tab()

        with document_tab:
            self.handle_document_tab()

    def get_table_info(self, tables_info: dict):
        all_tables_info = ""
        include_user_define_note = False
        
        for table_name, full_table_info in tables_info.items():
            table_summary = full_table_info.get("table_summary", "")
            df = pd.DataFrame(full_table_info.get("table_columns_info", []))

            # Step 1: Drop fully empty columns BEFORE filtering rows
            df = df.replace(r'^\s*$', np.nan, regex=True)
            filtered_data_df = df.dropna(axis=1, how="all")

            # Step 2: Removes rows where all other columns except 'Dataset Column Name' are NaN.
            filtered_data_df = filtered_data_df[filtered_data_df.drop(columns=['Dataset Column Name']).notna().any(axis=1)]

            # Check if user defined name is provided
            if 'User Define Column Name' in filtered_data_df.columns and \
            filtered_data_df['User Define Column Name'].fillna("").str.strip().any():
                include_user_define_note = True

            # Step 3: Convert to JSON format
            extra_info_json = filtered_data_df.to_json(orient="records", indent=2)

            # Step 4: Organize the info
            all_tables_info += f"Table {table_name}\n"

            if table_summary:
                all_tables_info += f"Summary\n{table_summary}\n\n"

            all_tables_info += f"### Table Context Information\n{extra_info_json}\n"
            all_tables_info += "### End of Context\n\n"

        # Add prefix explanation
        explanation =""
        if include_user_define_note:
            explanation += (
                "- 'Dataset Column Name' refers to the original column name in the dataset.\n"
                "- 'User Define Column Name' is a clearer or more descriptive name provided by the user. "
                "Prefer this name when constructing SQL queries if it exists.\n"
            )
        explanation += (
            "- Use 'Description' for semantic meaning.\n"
            "- Use 'Calculation/Formula' for relevant logic in queries.\n\n"
        )

        return explanation + all_tables_info
    
    def generate_dataset_overview(self):
        # Generate a sumamry & question recommendations for CSV
        num_rows = min(len(st.session_state.df), 11)
        sample_dataset = st.session_state.df[:num_rows]
        sample_dataset_str = sample_dataset.to_csv(sep="|", index=False, lineterminator="\n")

        # Main function to run tasks concurrently
        async def main(llm, sample_dataset_str, rows, cols, schema):
            # Run tasks concurrently using asyncio.gather
            self.app.logger.debug("Starting concurrent execution of summary and question recommendations...")
            excel_summary, question_recommendations = await asyncio.gather(
                dataset_summary_async(llm, sample_dataset_str, rows, cols, schema),
                generate_question_recommendations_async(llm, sample_dataset_str)
            )
            self.app.logger.debug("Concurrent execution completed.")
            return excel_summary, question_recommendations

        # Run the async main function
        excel_summary, question_recommendations = asyncio.run(
            main(st.session_state.llm, sample_dataset_str, st.session_state.df.shape[0], st.session_state.df.shape[1], st.session_state.schema)
        )

        self.app.logger.debug(f"Excel Summary: {excel_summary}")
        self.app.logger.debug(f"Question Recommendation: {question_recommendations}")

        for key, value in {"excel_summary": excel_summary, "question_recommendations": question_recommendations}.items():
            if value:
                st.session_state[key] = value

    def react_agent_toolkit(self, retriever_top_k_documents: str, additional_feedbacks: Optional[str] = None):
        """
        Creates and configures a ReAct agent toolkit with SQL, Python execution, and response validation capabilities.

        This agent is designed to interact with a database, with tools: SQLDatabaseToolkit and FollowUpQuestionTool.

        Args:
            retriever_top_k_documents (str): A string containing the top-k related documents retrieved from the vector store.
            additional_feedbacks: (Optional) Additional feedback or context provided from user to be included in the prompt template.

        Returns:
            AgentExecutor: An agent executor capable of handling complex queries and reasoning through multiple tools.
        """
        db_toolkit = SQLDatabaseToolkit(db=st.session_state.db, llm=st.session_state.llm)
        tools = db_toolkit.get_tools()
        
        # Get the latest k pairs of messages from the chat history
        paired_history_messages = []
        latest_k_chat_history = ""

        try: 
            for i in range(1, len(st.session_state.messages) - 1, 2):
                if st.session_state.messages[i]['role'] == "user" and st.session_state.messages[i+1]['role'] == "assistant":
                    paired_history_messages.append((st.session_state.messages[i]['content'], st.session_state.messages[i + 1]['content']))
        except Exception as e:
            st.error(f"Error while pairing messages: {e}")

        latest_k_pairs = paired_history_messages[-st.session_state.k:]
        
        for idx, (human, ai) in enumerate(latest_k_pairs, 1):
            latest_k_chat_history += f"--- Chat {idx} ---\n"
            latest_k_chat_history += f"User: {human}\n"
            try:
                # Attempt to parse the assistant response as JSON
                content_json = json.loads(ai)
                sql = content_json.get("SQL")
                text_response = content_json.get("TextResponse")
                if sql:
                    latest_k_chat_history += f"Assistant (SQL): {sql}\n\n"
                else:
                    latest_k_chat_history += f"Assistant (TextResponse): {text_response}\n\n"
            except json.JSONDecodeError:
                latest_k_chat_history += f"Assistant: {ai}\n\n"

        # Get the table info
        table_info_prompt_template = ""
        if st.session_state.tables_info and len(st.session_state.tables_info) > 0:
            all_tables_info = self.get_table_info(st.session_state.tables_info)
            table_info_prompt_template += "\nThe following context provides detailed information about the database tables and their columns.\n"
            table_info_prompt_template += "Use this information to accurately generate SQL queries.\n"
            table_info_prompt_template += "## Table Context Information\n"
            table_info_prompt_template += f"\n{all_tables_info}"

        prompt_template = PromptTemplate.from_template(
            TEXT_TO_SQL_TO_CHART_PROMPT_TEMPLATE,
            partial_variables={
                "python_plot_instructions": PYTHON_PLOT_PROMPT_TEMPLATE, 
                "table_names": st.session_state.db.get_table_names(),
                "db": st.session_state.db, 
                "top_k": str(10), 
                "dialect": st.session_state.db.dialect,
                "retriever_top_k_documents": retriever_top_k_documents,
                "additional_table_info": table_info_prompt_template,
                "additional_feedbacks": additional_feedbacks,
                "plotly_unique_key": str(int((len(st.session_state.messages) + 1)/2)),
                "chat_history": latest_k_chat_history,
            },
        )
        self.app.logger.debug(f"Prompt Template: \n{prompt_template.template}")
       
        react_agent = create_react_agent(
            llm = st.session_state.llm, 
            tools = tools, 
            prompt = prompt_template, 
        )

        agent_executor = AgentExecutor(
            agent = react_agent, 
            tools = tools, 
            verbose = True,
            memory = st.session_state.memory,
            handle_parsing_errors = True,
            max_iteration = 50, 
            max_execution_time = 500,
            return_intermediate_steps = True
        )
        return agent_executor
    
    def rag_top_k_related_documents(self, query: str, k: int = 3) -> str:
        """
        Retrieves the top k related documents from the vector store based on the user's query.

        Args:
            query (str): The user's query to search for related documents.
            k (int, optional): The number of top related documents to retrieve. Defaults to 5.

        Returns:
            str: A str of top-k retriever documents based on the user's query.
        """
        try:
            if "retriever" in st.session_state:
                retriever_results = st.session_state.retriever.invoke(query)[:k]
                formatted_retriever_results = "\n\n".join(
                    f"Doc {i+1}:\n{doc.page_content}\nMetadata: {doc.metadata}"
                    for i, doc in enumerate(retriever_results)
                )
                return formatted_retriever_results
            else:
                return ""
        except Exception as e:
            st.error(f"Error while retrieving the top-k documents: {e}")
    
    def regenerate_final_answer_prompt(self, regenerate_query_context: str):
        return f"""
            ### Additional User Feedback:
            The user provided feedback on the previous question. This could be:
            - A corrected SQL query provided by the user if the generated one was wrong.
            - An explanation from the user if the original question was flawed or unanswerable. 
            (Note: The user might also provide an invalid or incorrect explanation â€” you must validate it logically based on the question and schema.)

            {regenerate_query_context}
        """
    
    def fix_final_answer(self, original_response: str, error_msg: str):
        """
        Use LLM to fix the final response if parsing fails.
        
        Args:
            original_response (str): The original response generated by the LLM.
            error_message (str): The error message encountered during parsing.

        Returns:
            str: The corrected response in the required JSON format.
        """
        try:
            fixed_prompt_template = ChatPromptTemplate.from_template(FIX_FINAL_RESPONSE_TEMPLATE)
            chain = fixed_prompt_template | st.session_state.llm | StrOutputParser()
            fixed_response = chain.invoke({"original_response": original_response, "error_message": error_msg})
            self.app.logger.debug(f"Fixed Response: {fixed_response}")

            return fixed_response
        
        except Exception as e:
            st.error(f"An error occured while fixing the final answer.{e}")
    
    def invoke_agent_response(self, agent_executor: AgentExecutor, user_query: str, user_feedback:str = "", is_user_feedback = False):
        """
        Invokes the agent to (1) generates a response, (2) parse the final answer in pydantic format, (3) display the final answer in UI, (4) saves it to messages.
        Args:
            agent_executor (AgentExecutor): The agent executor configured with tools and prompts.
            user_query (str): The query provided by the user.
            user_feedback (bool, optional): Indicates if the query includes user feedback. Defaults to False.
        """

        if is_user_feedback:
            query_input = f"Previous User Question: {user_query}\nCurrent User Feedback or Request: {user_feedback}"
            return_message = user_feedback
        else:
            query_input = return_message = user_query

        response_text = agent_executor.invoke({"input": query_input})
        return return_message, response_text
    
    def final_response_output_parser(self, response_text: str):
        """ 
        Parses the final output from the agent's response text into a structured format using Pydantic.

        Args:
            response_text (dict): The output text from the agent's response.

        Returns:
            tuple: A tuple containing the SQL query, text response, code block, agent thinking process, saved user message, and final answer in string format.
        """
        print(f"Response Text: {response_text}")
        output_parser = PydanticOutputParser(pydantic_object=FinalAnswerFormat)
        final_answer_pydantic_format = output_parser.invoke(response_text)
        
        sql = final_answer_pydantic_format.SQL
        text_response = final_answer_pydantic_format.TextResponse
        code_block = final_answer_pydantic_format.Code
        follow_up_questions = final_answer_pydantic_format.FollowUpQuestions

        self.app.logger.debug(f"Final Answer: \n{final_answer_pydantic_format}")

        final_answer_str_format = json.dumps(final_answer_pydantic_format.dict(), indent=4)
        st.session_state.feedback = None
        return sql, text_response, code_block, follow_up_questions, final_answer_str_format
    
    def saved_user_message(self, user_query: str, final_answer_str_format: str, agent_thoughts: str):
        """
        Saves the user query and the final answer in the session state messages.

        Args:
            user_query (str): The original query provided by the user.
            final_answer_str_format (str): The final answer in string format.
            agent_thoughts (str): The agent's reasoning or steps taken to arrive at the final answer.
        """
        st.session_state.messages.append({"role": "user", "content": user_query})
        st.session_state.messages.append({"role": "assistant", "content": final_answer_str_format, "agent_thinking_process": agent_thoughts})

    def display_feedback_form(self, user_query: str):
        """
        Displays a feedback form for users to provide feedback on the LLM response.

        The feedback form allows users to:
        - Provide a thumbs-up or thumbs-down rating for the response.
        - Optionally include a reason for their feedback or suggest a corrected SQL query if the response was incorrect.

        Args:
            user_query (str): The original query provided by the user, used to regenerate the response if feedback is submitted.
        """  
        message_index = int((len(st.session_state.messages) + 1)/2)
        key = f"feedback_{message_index}"
        with st.form(f"feedback_form_{message_index}"):
            streamlit_feedback(feedback_type="thumbs", optional_text_label="[Optional] ðŸ‘ Save this response for feedback reference ðŸ‘Ž Regenerate or provide corrections", align="flex-start", key=key)
            st.form_submit_button('Submit Response', on_click=lambda: self.handle_user_feedback(user_query, message_index)) 

    def add_documents_to_vector_store(self, sql_query_documents: list, uuids: list):
        st.session_state.vector_store.add_documents(documents=sql_query_documents, ids=uuids)
        st.session_state.sql_query_documents.append(sql_query_documents[0])
        self.app.logger.info(f"Add Documents into Vector Store: \n{sql_query_documents}")
        bm25_retriever = BM25Retriever.from_documents(st.session_state.sql_query_documents)
        st.session_state.retriever = EnsembleRetriever(
            retrievers = [bm25_retriever, st.session_state.vector_store.as_retriever()],
            weights = [0.3, 0.7]
        )
        st.success("Document saved successfully! Document has been added and stored in the vector store for future reference.")

    def handle_user_feedback(self, user_query: str, message_index: int):
        """
        Handles user feedback for the last generated response and regenerates the agent's response based on the feedback.

        This method retrieves the last message from the session's chat memory, extracts the context of the previous 
        response (e.g., SQL query or answer), and combines it with the user's feedback. It then uses this information 
        to regenerate a new response by invoking the agent with the updated context.

        Args:
            user_query (str): The original query provided by the user.
        """
        if not len(st.session_state.memory.chat_memory.messages) > 0:
            return
        
        last_message = st.session_state.memory.chat_memory.messages[-1]
        feedback_response = ""
 
        if hasattr(last_message, "content") and last_message.content:
            try:
                final_answer = json.loads(last_message.content)
                sql_query = final_answer.get("SQL", None)
                text_response = final_answer.get("TextResponse", None)
                feedback_response = (f"\n Previous SQL Query or Previous Answer: {sql_query if sql_query else text_response}")
            except:
                feedback_response = (f"\n Previous SQL Query or Previous Answer: {last_message.content}")

            feedback_key = f"feedback_{message_index}"
            if feedback_key not in st.session_state:
                return
            
            feedback = st.session_state[feedback_key]
            if not feedback:
                return
        
            feedback_score = feedback['score']
            feedback_text = feedback['text']
         
            # If the feedback is thumbs down, regenerate the response
            if feedback_score == "ðŸ‘Ž":
                if feedback_text:
                    feedback_response += f"\n Current User Feedback or Request: {feedback_text}"
                else:
                    feedback_response += f"\n Current User Feedback or Request: The previous answer is not satisfactory. Please re-check the user request and provide a better response."

                retriever_top_k_documents = self.rag_top_k_related_documents(feedback_response)
                agent_executor = self.react_agent_toolkit(retriever_top_k_documents = retriever_top_k_documents, additional_feedbacks = self.regenerate_final_answer_prompt(feedback_response))
                user_query, response_output = self.invoke_agent_response(agent_executor, user_query, feedback_text, is_user_feedback = True)
                sql, text_response, code_block, follow_up_questions, final_answer_str_format = self.final_response_output_parser(response_output["output"])
                self.saved_user_message(user_query, final_answer_str_format, response_output["intermediate_steps"])
            else:
                # If the feedback is thumbs up, saved the response into the vector store
                # TODO: Handle the case where if the response is feedback then cannot save to vector store
                sql_query_document = [Document(page_content=f"User Query: {user_query}\nSQL Query: {sql_query}", metadata={"source": st.session_state.file_name})]
                uuids = [str(uuid4())]
                self.add_documents_to_vector_store(sql_query_document, uuids)

        st.session_state.feedback = True

    def _render_agent_thinking(self, agent_thoughts):
        st.markdown("""
            <style>
            div[data-testid="stExpander"] div[role="button"] p {
                font-size: 1.2rem;
                font-weight: bold;
            }
            pre code {
                white-space: pre-wrap !important;
            }
            </style>
        """, unsafe_allow_html=True)

        for i, step in enumerate(agent_thoughts, 1):
            with st.expander(f"Step {i}: Thinking Process", expanded=False):
                if isinstance(step, tuple) and len(step) >= 2:
                    action, observation = step[0], step[1]
                    st.markdown(f"*Action:* {action.tool}")
                    st.markdown(f"*Input:*\n\n{action.tool_input}\n")
                    st.markdown(f"*Observation:*\n\n{observation}\n")
                else:
                    st.json(step)
                    
    def display_response(self, sql: List[str], response: str, code_block: str, follow_up_questions: List[str], agent_thoughts: str = None):
        """
        Displays the response from an SQL query or a generated result, optionally rendering a visualization.

        Args:
            sql (str): The SQL query used to generate the response.
            response (str): The textual response generated from the SQL query or retrieval process.
            code_block (str): A Python code block that generates a visualization.
            agent_thoughts (str, optional): Agent's reasoning or steps.
        """
        try:
            print("SQL: ", sql)
            print(type(sql))
            print()
            print("Response: ", response)
            print(type(response))
            print()
            print("Code Block: ", code_block)
            print(type(code_block))
            print()
            print("Follow Up Questions: ", follow_up_questions)
            print(type(follow_up_questions))
            print()
            print("Agent Thoughts: ", agent_thoughts)
            print(type(agent_thoughts))
            print()

            sql_is_blank = len(sql) == 0  
            code_is_blank = not code_block.strip() 

            # If both SQL and code are blank, show response only
            if sql_is_blank and code_is_blank and len(follow_up_questions) == 0:
                st.markdown(f"Response:\n{response}")
                return

            elif not code_is_blank:
                # Compile and show full tabs if code is present
                compiled_code = compile(code_block, '<string>', 'exec')
                chart_tab, sql_tab, code_tab, followup_tab, agent_tab = st.tabs([
                    "ðŸ“Š Chart", "ðŸ›¢ SQL", "ðŸ’» Code", "ðŸ’¡ Follow Up Analysis Questions", "ðŸ§  Agent Thinking"
                ])

                with chart_tab:
                    local_scope = {}
                    exec(code_block, {}, local_scope)

                with sql_tab:
                    if not sql_is_blank:
                        for query in sql:
                            st.code(query, language="sql")
                    if response and "blank" not in response.lower():
                        st.markdown(f"Response: \n{response}")

                with code_tab:
                    formatted_code = code_block.replace(";", ";\n").replace("import", "\nimport")
                    st.code(formatted_code, language="python")

                with followup_tab:
                    if follow_up_questions:
                        for question in follow_up_questions:
                            st.markdown(f"- {question}")
                    else:
                        st.info("No follow-up questions generated.")

                with agent_tab:
                    if agent_thoughts:
                        self._render_agent_thinking(agent_thoughts)
                    else:
                        st.info("No agent reasoning provided.")
            else:
                # If code is blank, show only SQL and Agent tabs
                sql_tab, followup_tab, agent_tab = st.tabs(["ðŸ›¢ SQL", "ðŸ’¡ Follow Up Analysis Questions", "ðŸ§  Agent Thinking"])

                with sql_tab:
                    if not sql_is_blank:
                        for query in sql:
                            st.code(query, language="sql")
                    if response and "blank" not in response.lower():
                        st.markdown(f"Response: \n{response}")

                    with followup_tab:
                        if len(follow_up_questions) > 0:
                            for question in follow_up_questions:
                                st.markdown(f"- {question}")
                        else:
                            st.info("No follow-up questions generated.")

                with agent_tab:
                    if agent_thoughts:
                        self._render_agent_thinking(agent_thoughts)
                    else:
                        st.info("No agent reasoning provided.")
        except Exception as e:
            st.error(f"An error occurred while displaying the response: {e}")

    def handle_response_tab(self):
        if "data" not in st.session_state and "db" not in st.session_state:
            st.warning(WARNING_MESSAGE)
        elif "llm" not in st.session_state:
            st.warning("Please enter the API key to start conversation")
        else:
            if "messages" not in st.session_state:
                st.session_state["messages"] = [{"role": "assistant", "content": "Hello! I'm your SQL Assistant. How can I assist you today?"}]
                self.app.logger.debug("Session messages initialized.")
                st.session_state["selected_mode"] = "SQL to Chart ðŸ“Š" 

            if "excel_summary" in st.session_state:
                summary_html = st.session_state.excel_summary.replace("\n", "<br>")

                with st.expander("ðŸ“ƒ Data Summary"):
                    st.markdown(f"""<p style="font-size: 11px; color: gray;"> An enriched data summary with semantic types and descriptions.</p>""",unsafe_allow_html=True)
                    st.markdown(
                        f"""
                        <div style="font-size: 11px; color: gray; text-align: justify; background-color: #f0f0f0; border-radius: 8px; padding: 10px; ">
                            {summary_html} 
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                
            if "question_recommendations" in st.session_state:
                grouped_questions = {}
                # Organize questions by category
                for item in st.session_state.question_recommendations["questions"]:
                    category = item["category"]
                    question = item["question"]
                    
                    if category not in grouped_questions:
                        grouped_questions[category] = []
                    grouped_questions[category].append(question)

                with st.expander("ðŸ’¡ Goal Exploration"):
                    st.markdown(f"""<p style="font-size: 11px; color: gray;"> A list of automatically generated data exploration goals based on the dataset given.</p>""",unsafe_allow_html=True)
                    categories = list(grouped_questions.keys())  
                    num_columns = 3 
                    columns = st.columns(num_columns)  

                    # Iterate over categories and distribute them in columns
                    for index, category in enumerate(categories):
                        col = columns[index % num_columns]  
                        with col.container():
                            st.markdown(
                                f"""
                                <div style="border-radius: 8px; padding-left: 10px; background-color: #f9f9f9; 
                                            box-shadow: 2px 2px 5px rgba(0,0,0,0.1); width: 100%;">
                                    <h4 style="color: #333; font-size: 13px; font-weight: bold; margin: 0;">{category}</h4>
                                </div>
                                <div style="padding-left: 15px; margin-top: 5px;">
                                    <ul style="padding-left: 15px; color: #333;">
                                        {''.join(f'<li style="margin-bottom: 4px; font-size: 11px; text-align: justify;">{question}</li>' for question in grouped_questions[category])}
                                    </ul>
                                </div>
                                """,
                                unsafe_allow_html=True
                            )

            # Display chat history
            last_query = ""
            for idx, message in enumerate(st.session_state.messages):
                role = message.get("role")
                if role == "user":
                    with st.chat_message("user"):
                        content = message["content"]
                        last_query = content
                        st.write(content)

                if role == "assistant":
                    with st.chat_message("assistant"):
                        content = message["content"]
                        try:
                            # Converts the str response to dict format
                            content_json = json.loads(content)
                            self.app.logger.debug(f"Content JSON: {content_json}")
                            self.display_response(content_json['SQL'], content_json['TextResponse'], content_json['Code'], content_json['FollowUpQuestions'], message["agent_thinking_process"])
                        except:
                            st.write(content)

            if len(st.session_state.messages) > 1 and st.session_state.feedback:
                self.display_feedback_form(last_query)
                st.session_state.feedback = False

            # Style to fix the chatbot position
            st.markdown(
                """
                <style>
                /* Chat input box */
                .stChatInput {
                    position: fixed;
                    bottom: 25px; 
                    left: 350px; 
                    width: calc(100% - 350px);
                    background-color: white;
                    padding: 10px;
                    box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.1);
                    z-index: 1000;
                    border-radius: 10px;
                }

                /* Disclaimer text */
                .disclaimer {
                    position: fixed;
                    bottom: 0px; 
                    margin-bottom: -5px;
                    left: 350px;
                    width: calc(100% - 350px);
                    font-size: 11px;
                    color: gray;
                    text-align: center;
                    background-color: white;
                    padding: 5px 10px;
                    z-index: 999; /* Lower z-index to stay below chat input */
                }

                /* Radio button styling */
                .stRadio > div {
                    display: flex;
                    gap: 10px;
                    align-items: center;
                    margin-bottom: 10px;
                }
                </style>
                """,
                unsafe_allow_html=True,
            )

            st.markdown(
                """
                <p class="disclaimer">
                    <strong> Disclaimer:</strong> Gen BI system may make mistakes; review results and use your judgment. 
                </p>
                """,
                unsafe_allow_html=True,
            )

            user_query = st.chat_input(placeholder="Ask me anything!")

            if user_query:
                st.chat_message("user").write(user_query)
                with st.chat_message("assistant"):
                    with st.spinner("We are preparing a response to your question. Please allow up to one minute for completion...."):
                        MAX_RETRIES = 3
                        attempt = 0
                        while attempt < MAX_RETRIES:
                            try:
                                # Invoke the agent response
                                retriever_top_k_documents = self.rag_top_k_related_documents(user_query)
                                agent_executor = self.react_agent_toolkit(retriever_top_k_documents = retriever_top_k_documents)

                                # Get the prompt template
                                user_query, response_output = self.invoke_agent_response(agent_executor, user_query)
                                sql, text_response, code_block, follow_up_questions, final_answer_str_format = self.final_response_output_parser(response_output["output"])
                                self.display_response(sql, text_response, code_block, follow_up_questions, response_output["intermediate_steps"])
                                self.saved_user_message(user_query, final_answer_str_format, response_output["intermediate_steps"])
                                self.display_feedback_form(user_query)
                                break
                            except Exception as e:
                                try:
                                    self.app.logger.error(f"Error while generating response. Now fixing: {e}")
                                    attempt += 1
                                    fix_output = self.fix_final_answer(original_response=response_output["output"], error_msg=e)
                                    sql, text_response, code_block, follow_up_questions, final_answer_str_format = self.final_response_output_parser(fix_output)
                                    self.display_response(sql, text_response, code_block, follow_up_questions, response_output["intermediate_steps"])
                                    self.saved_user_message(user_query, final_answer_str_format, response_output["intermediate_steps"])
                                    break
                                except Exception as e:
                                    st.error(f"Error while processing response: {e}")
                                    break
                        else:
                            st.error("Failed to generate a response after multiple attempts. Please check your query or try again later.")
                            self.app.logger.error("Failed to generate a response after multiple attempts.")

    def handle_data_tab(self):
        if ("data" not in st.session_state) and ("db" not in st.session_state):
            st.warning(WARNING_MESSAGE)
            return 
        
        st.write("#### Dataset Table Selection")
        tables = st.session_state.sql_inspector.get_table_names()
        self.app.logger.info(f"Tables in database: {tables}")
        selected_table = st.selectbox("Choose a table from the database for Data Preview:", tables)
        st.session_state.df = pd.read_sql(f'SELECT * FROM "{selected_table}"', st.session_state.db._engine)
        st.session_state.df = st.session_state.df.dropna(axis=1, how="all")
        total_rows = st.session_state.df.shape[0]

        # Default values
        table_summary = ""
        editable_data = None

        # Check if saved file exists
        json_path = f"data/{selected_table}.json"
        if os.path.exists(json_path):
            with open(json_path, "r") as f:
                saved_data = json.load(f)

            if selected_table in saved_data:
                full_table_info = saved_data[selected_table]
                table_summary = full_table_info.get("table_summary", "")
                editable_data = pd.DataFrame(full_table_info.get("table_columns_info", []))

                # Update the table variable
                st.session_state.tables_info[selected_table] = full_table_info
                
        with st.form("table_data"):
            # Allow user to provide a short table summary
            st.write("#### Table Summary")
            st.write("[Optional] Briefly describe what this table is about.")
            table_summary = st.text_area("", placeholder="This table contains sales data for Q1 2025, including product details and revenue.")

            # Create a table with original column names, editable user input column names, descriptions, and formulas
            original_columns = st.session_state.df.columns.tolist()

            # Create a blank editable table only if no data was loaded
            if editable_data is None:
                editable_data = pd.DataFrame({
                    "Dataset Column Name": original_columns,  
                    "User Define Column Name": [""] * len(original_columns), 
                    "Description": [""] * len(original_columns), 
                    "Calculation/Formula": [""] * len(original_columns) 
                })
                
            st.write("#### Table Data")
            st.write("[Optional] Edit the full column names, add descriptions, or define formulas as needed.")
            edited_table_data = st.data_editor(
                editable_data,
                num_rows = "fixed",
                use_container_width=True,
                column_config={
                    "Dataset Column Name": st.column_config.Column(disabled=True, width="fit"), 
                    "User Define Column Name": st.column_config.Column(width="fit"),
                    "Description": st.column_config.Column(width=400),
                    "Calculation/Formula": st.column_config.Column(width=400)
                }
            )

            # Process the edited data
            if st.form_submit_button("Save Changes"):
                # Save all information together
                full_table_info = {
                    "table_name": selected_table,
                    "table_summary": table_summary,
                    "table_columns_info": edited_table_data.to_dict(orient="records")
                }
                st.session_state.tables_info[selected_table] = full_table_info

                # Save as JSON file
                with open(f"data/{selected_table}.json", "w") as f:
                    json.dump(st.session_state.tables_info, f, indent=2)

        st.divider()

        # Step 1: Filter Col
        st.write("#### Data Filter and Preview")
        with st.form("search_form"):
            total_rows = st.session_state.df.shape[0]
            selected_columns = st.multiselect("ðŸ“Œ Select Columns for Display", st.session_state.df.columns.tolist(), default=st.session_state.df.columns.tolist())
            row_col, display_col = st.columns([1, 1])
            with row_col:
                display_rows = st.number_input("ðŸ”¹ Enter the number of rows to display:", placeholder="5", min_value=1, max_value=total_rows, value=min(10, total_rows))
            
            with display_col:
                search_query = st.text_input("ðŸ”¹ Filter dataset by value:", "", placeholder="ðŸ” Enter the filter value you want to search in dataset")
            
            submitted = st.form_submit_button("Search")

            if submitted:
                if search_query:
                    filtered_df = st.session_state.df[selected_columns][st.session_state.df[selected_columns].apply(lambda row: row.astype(str).str.contains(search_query, case=False).any(), axis=1)]
                else:
                    filtered_df = st.session_state.df[selected_columns]
                
                # Reset index to start from 1
                filtered_df.index = pd.RangeIndex(start=1, stop=len(filtered_df) + 1, step=1)
                st.dataframe(filtered_df.head(display_rows))
                st.session_state.df = filtered_df
            else:
                # Reset index before displaying
                preview_df = st.session_state.df[selected_columns]
                preview_df.index = pd.RangeIndex(start=1, stop=len(preview_df) + 1, step=1)

                st.dataframe(preview_df.head(display_rows))
                st.session_state.df = preview_df

            st.write(f"*Total Dataset Rows:* {total_rows}; *Display Rows:* {display_rows}")

        # Export to CSV
        csv = st.session_state.df.to_csv(index=False)
        st.download_button(
            label = "Export to CSV",
            data=csv,
            file_name="exported_data.csv"
        )

        # Step 2: Show table information by using df.info
        buffer = pd.io.common.StringIO()  
        st.session_state.df.info(buf=buffer)
        info_text = buffer.getvalue().split("\n")

        columns = []
        for line in info_text[5:-3]:
            parts = line.split()
            if len(parts) >= 4:
                col_name = parts[1]  # Column name
                non_null_count = parts[-3] + " " + parts[-2]  # Non-null count (e.g., "1000 non-null")
                dtype = parts[-1]  # Data type
                columns.append([col_name, non_null_count, dtype])
        
        df_info = pd.DataFrame(columns, columns=["Feature", "Non-Null Count", "Data Type"])
        df_info["Unique Count"] = df_info["Feature"].apply(lambda col: st.session_state.df[col].nunique(dropna=True))
        df_info["Unique Values"] = df_info["Feature"].apply(
            lambda col: ", ".join(map(str, st.session_state.df[col].dropna().unique()))
            if st.session_state.df[col].nunique(dropna=True) <= 10
            else "The feature has high cardinality; unique values greater than 10 are not displayed."
        )

        def highlight_missing(val):
            count = int(val.split(" ")[0])  # Extract missing count
            color = "green" if count == 0 else "red"
            return f"background-color: {color}; color: white;"
        
        # Missing (null/NaN) Count: np.nan or None
        df_info["Null Count"] = df_info["Feature"].apply(
            lambda col: st.session_state.df[col].isna().sum()
        )

        # Empty String Count: Value present but is ""
        df_info["Empty Count"] = df_info["Feature"].apply(
            lambda col: (st.session_state.df[col].str.strip() == "").sum()
            if st.session_state.df[col].dtype == 'object'
            else 0
        )

        total_rows = len(st.session_state.df)
        def calculate_missing_count(col):
            series = st.session_state.df[col]
            if series.dtype == 'object':
                missing = (series.isna() | (series.str.strip() == "")).sum()
            else:
                missing = series.isna().sum()
            percent = (missing / total_rows) * 100
            return f"{missing} ({percent:.2f}%)"

        df_info["Missing Count"] = df_info["Feature"].apply(calculate_missing_count)

        # Step 3: Show Data Shape
        st.divider()
        st.write("#### Data Shape")
        st.write(f"Number of Rows: {st.session_state.df.shape[0]}, Number of Columns: {st.session_state.df.shape[1]}")

        # Step 4: Data Overview
        st.divider()
        st.write("#### Data Overview")
        df_info.index = pd.RangeIndex(start=1, stop=len(df_info) + 1, step=1)  
        st.dataframe(df_info.style.applymap(highlight_missing, subset=["Missing Count"]))
        st.markdown(f"There are *{st.session_state.df.duplicated().sum()}* duplicated row(s) in this {selected_table} table.")
        
        # Step 5: Data Description
        st.divider()
        st.write("#### Data Description")
        st.write(st.session_state.df.describe())

    def handle_document_tab(self):
        """
        Displays the sql_query_documents in a table format inside the Document Tab.
        """
        if ("data" not in st.session_state) and ("db" not in st.session_state):
            st.warning(WARNING_MESSAGE)
            return 
    
        chromadb_client = chromadb.PersistentClient(path="vector_store")
        st.markdown(st.session_state.file_name)
        collection = chromadb_client.get_or_create_collection(name=st.session_state.file_name)
        st.session_state.vector_store = Chroma(collection_name=st.session_state.file_name, embedding_function=st.session_state.embedding_function, persist_directory="vector_store")
        st.session_state.sql_query_documents = st.session_state.vector_store.similarity_search("", k=1000)

        if len(st.session_state.sql_query_documents) > 0:
            bm25_retriever = BM25Retriever.from_documents(st.session_state.sql_query_documents)
            st.session_state.retriever = EnsembleRetriever(
                retrievers = [bm25_retriever, st.session_state.vector_store.as_retriever()],
                weights = [0.3, 0.7]
            )

        st.write("### ðŸ“„ SQL Query Documents")

        # --- Add new document form ---
        with st.form("add_sql_query_document"):
            user_query_input = st.text_area("User Query", placeholder="Enter your question here")
            sql_query_input = st.text_area("SQL Query", placeholder="Enter the SQL query here")
            confirm_save = st.checkbox("I confirm I want to save this document.")
            submitted = st.form_submit_button("Add Document")

            if submitted:
                if not (user_query_input.strip() and sql_query_input.strip()):
                    st.warning("Please fill in both fields.")
                elif not confirm_save:
                    st.warning("Please confirm you want to save this document.")
                else:
                    page_content = f"User Query: {user_query_input.strip()}\nSQL Query: {sql_query_input.strip()}"
                    new_doc = [Document(page_content=page_content, metadata={"source": st.session_state.file_name})]
                    uuids = [str(uuid4())]
                    self.add_documents_to_vector_store(new_doc, uuids)

        # --- Search for similar documents ---
        st.divider()
        st.write("#### ðŸ” Search SQL Query Documents by Question")
        search_query = st.text_area("Enter a question to search for similar SQL queries", key="search_sql_doc")
        if st.button("Search Similar Documents"):
            if search_query.strip():
                # Use retriever to get top 5 similar documents
                similar_docs = st.session_state.retriever.invoke(search_query.strip())
                if similar_docs:
                    st.success(f"Top {len(similar_docs)} similar results:")
                    doc_data = []
                    for doc in similar_docs:
                        question = ""
                        answer = ""
                        if hasattr(doc, "page_content") and isinstance(doc.page_content, str):
                            parts = doc.page_content.split("SQL Query:", 1)
                            if len(parts) == 2:
                                question = parts[0].replace("User Query:", "").strip()
                                answer = parts[1].strip()
                            else:
                                question = doc.page_content.strip()
                        doc_data.append({
                            "User Query": question,
                            "SQL Query": answer,
                            "Database": doc.metadata.get("source", "")
                        })
                    df = pd.DataFrame(doc_data)
                    df.index = range(1, len(df) + 1)
                    st.dataframe(df, use_container_width=True)
                else:
                    st.info("No similar documents found.")
            else:
                st.warning("Please enter a question to search.")

        documents = getattr(st.session_state, "sql_query_documents", [])
        if not documents:
            st.info("No documents found in the vector store.")
            return

        # ---Display the SQL Documents ---
        doc_data = []
        for doc in documents:
            question = ""
            answer = ""
            # Parse the page_content
            if hasattr(doc, "page_content") and isinstance(doc.page_content, str):
                parts = doc.page_content.split("SQL Query:", 1)
                if len(parts) == 2:
                    question = parts[0].replace("User Query:", "").strip()
                    answer = parts[1].strip()
                else:
                    question = doc.page_content.strip()
            doc_data.append({
                "User Query": question,
                "SQL Query": answer,
                "Database": doc.metadata.get("database", doc.metadata.get("source", "")) if hasattr(doc, "metadata") else ""
            })

        df = pd.DataFrame(doc_data)
        df.index = range(1, len(df) + 1) 
        st.dataframe(df, use_container_width=True)